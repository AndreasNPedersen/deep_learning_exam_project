{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import string\n",
    "import random\n",
    "import sys\n",
    "import unidecode\n",
    "from datetime import datetime\n",
    "# from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device config\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of characters: 100\n"
     ]
    }
   ],
   "source": [
    "# get characters\n",
    "all_characters = string.printable\n",
    "n_characters = len(all_characters)\n",
    "print(f'number of characters: {n_characters}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file\n",
    "file = unidecode.unidecode(open('./data/alice_in_wonderland.txt').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# module\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embed = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(self.hidden_size * num_layers, output_size)\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        out = self.embed(x)\n",
    "        out, (hidden, cell) = self.lstm(out.unsqueeze(1), (hidden, cell))\n",
    "        # print(f'forward function: out.shape')\n",
    "        # print(out.shape)\n",
    "        out = self.fc(out.reshape(out.shape[0], -1))\n",
    "        return out, (hidden, cell)\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.num_layers * 2, batch_size, self.hidden_size).to(device)\n",
    "        cell = torch.zeros(self.num_layers * 2, batch_size, self.hidden_size).to(device)\n",
    "        return hidden, cell\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator():\n",
    "    def __init__(self):\n",
    "        self.chunk_len = 300\n",
    "        self.num_epochs = 4000\n",
    "        self.batch_size = 1\n",
    "        self.print_every = self.num_epochs // 25 or 1\n",
    "        self.hidden_size = 256\n",
    "        self.num_layers = 2\n",
    "        self.lr = 0.003\n",
    "\n",
    "\n",
    "    def char_tensor(self, string):\n",
    "        tensor = torch.zeros(len(string)).long()\n",
    "        for c in range(len(string)):\n",
    "            tensor[c] = all_characters.index(string[c])\n",
    "        return tensor\n",
    "\n",
    "\n",
    "    def get_random_batch(self):\n",
    "        start_idx = random.randint(0, len(file) - self.chunk_len)\n",
    "        end_idx = start_idx + self.chunk_len + 1\n",
    "        text_str = file[start_idx:end_idx]\n",
    "        text_input = torch.zeros(self.batch_size, self.chunk_len)\n",
    "        text_target = torch.zeros(self.batch_size, self.chunk_len)\n",
    "        for i in range(self.batch_size):\n",
    "            text_input[i,:] = self.char_tensor(text_str[:-1])\n",
    "            text_target[i,:] = self.char_tensor(text_str[1:])\n",
    "        return text_input.long(), text_target.long()\n",
    "\n",
    "\n",
    "    def generate(self, initial_str='i would like', predict_len=200, temperature=0.85):\n",
    "        hidden, cell = self.rnn.init_hidden(batch_size=self.batch_size)\n",
    "        initial_input = self.char_tensor(initial_str)\n",
    "        predicted = initial_str\n",
    "        \n",
    "        for p in range(len(initial_str) - 1):\n",
    "            _, (hidden, cell) = self.rnn(initial_input[p].view(1).to(device), hidden, cell)\n",
    "\n",
    "        last_char = initial_input[-1]\n",
    "        for p in range(predict_len):\n",
    "            output, (hidden, cell) = self.rnn(last_char.view(1).to(device), hidden, cell)\n",
    "            output_dist = output.data.view(-1).div(temperature).exp()\n",
    "            top_char = torch.multinomial(output_dist, 1)[0]\n",
    "            predicted_char = all_characters[top_char]\n",
    "            predicted += predicted_char\n",
    "            last_char = self.char_tensor(predicted_char)\n",
    "\n",
    "        return predicted\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        self.rnn = RNN(n_characters, self.hidden_size, self.num_layers, n_characters).to(device)\n",
    "        optimizer = torch.optim.Adam(self.rnn.parameters(), lr=self.lr)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        # writer = SummaryWriter(f'runs/alice0')\n",
    "        print(f'<{datetime.now()}>starting training')\n",
    "\n",
    "        for epoch in range(1, self.num_epochs + 1):\n",
    "            input, target = self.get_random_batch()\n",
    "            hidden, cell = self.rnn.init_hidden(batch_size=self.batch_size)\n",
    "\n",
    "            self.rnn.zero_grad()\n",
    "            loss = 0\n",
    "            input = input.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            for c in range(self.chunk_len):\n",
    "                # print(f'input.shape')\n",
    "                # print(input.shape)\n",
    "                # print(f'hidden.shape')\n",
    "                # print(hidden.shape)\n",
    "                # print(f'cell.shape')\n",
    "                # print(cell.shape)\n",
    "                output, (hidden, cell) = self.rnn(input[:, c], hidden, cell)\n",
    "                loss += criterion(output, target[:, c])\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss = loss.item() / self.chunk_len\n",
    "\n",
    "            if epoch % self.print_every == 0:\n",
    "                print(f'\\n\\n<{datetime.now()}> | epoch: {epoch}/{self.num_epochs} | loss: {loss}')\n",
    "                print(self.generate())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<2023-05-28 20:24:58.018391>starting training\n",
      "\n",
      "\n",
      "<2023-05-28 20:26:13.248390> | epoch: 160/4000 | loss: 1.8421734619140624\n",
      "i would like ta say tart opent it reegt?' but the Quell thable bas to say\n",
      "said\n",
      "the bot!  And be such, thing it's heer mirs the said hat to thing `I't be she\n",
      "ras im, and the Mething her those bregcexat a some crep\n",
      "\n",
      "\n",
      "<2023-05-28 20:27:32.211362> | epoch: 320/4000 | loss: 1.5943794759114582\n",
      "i would like the word the be, was go it was to bened of the groked to sound her she souse about was foll herself I pit to\n",
      "bines of their she gone, and they rest wren explen to the-ver the prised\n",
      "out in Alice of t\n",
      "\n",
      "\n",
      "<2023-05-28 20:28:52.131362> | epoch: 480/4000 | loss: 0.9546227010091146\n",
      "i would like a growled your she\n",
      "pight at as the was as first, `I've to she garmes, and as the\n",
      "Queen had it was said for little.\n",
      "\n",
      "  `Peraming Master was\n",
      "shouted to say\n",
      "wish she was to now on growify and the next,'\n",
      "\n",
      "\n",
      "<2023-05-28 20:30:11.417361> | epoch: 640/4000 | loss: 1.323508504231771\n",
      "i would like Alice,\n",
      "I was got they're all so growled arr askers.  The King's are a look to dried in a tone was replied of see a bit as fittoss\n",
      "voice loused, and care had had felt its glar the pore all a down dine\n",
      "\n",
      "\n",
      "<2023-05-28 20:31:29.542395> | epoch: 800/4000 | loss: 1.3921340942382812\n",
      "i would like the please, `I'm had not a nend up herself, and the thought Alice.\n",
      "\n",
      "  `We deal!            Tearly were sit, sWEE Caterpillant,' said the Knaves with their timid bits of the hook I'm sark deep said th\n",
      "\n",
      "\n",
      "<2023-05-28 20:32:50.227391> | epoch: 960/4000 | loss: 1.4872140502929687\n",
      "i would like like down, as it way im of you doing, Alice would not high, with a gone a song to\n",
      "hoped it it was\n",
      "you, pleases to down on a verse with\n",
      "were little sentch\n",
      "off the ringrabtiful Soup, reading four sour \n",
      "\n",
      "\n",
      "<2023-05-28 20:34:10.448359> | epoch: 1120/4000 | loss: 1.2797743733723959\n",
      "i would likely.\n",
      "\n",
      "  `Ow a\n",
      "mouth!'\n",
      "\n",
      "  `What you guite of the further does?' said the King to put one tunnel stoping all the great went on, you are,' said Alice.\n",
      "\n",
      "  She thought Alice, she way, and she this, when you\n",
      "\n",
      "\n",
      "<2023-05-28 20:35:30.317366> | epoch: 1280/4000 | loss: 1.2370817057291668\n",
      "i would like the he hush had great tossing.'\n",
      "\n",
      "  `I feet!' (he Gryphon and it had the feet high first, what the shouse saw the listened to her flarm.  Being?'  The King, she said the Sook and play saying no one of\n",
      "\n",
      "\n",
      "<2023-05-28 20:36:50.112360> | epoch: 1440/4000 | loss: 1.1597334798177084\n",
      "i would like they livedly\n",
      "speeched by running a great sudden\n",
      "their hands a moof evirect of great she general catches,' the\n",
      "Dight names:\n",
      "addence aded to herself, and dog you say:  `you go like another all this dos\n",
      "\n",
      "\n",
      "<2023-05-28 20:38:10.010391> | epoch: 1600/4000 | loss: 1.4214288330078124\n",
      "i would like the time, `they had fare, can't grin,' it quite memant things of her\n",
      "argument growing, out as pressed, the Queen:  she said, hoped Alice, pleased along and nowelved into think her die-chapidened do:-\n",
      "\n",
      "\n",
      "<2023-05-28 20:39:28.370360> | epoch: 1760/4000 | loss: 1.0712959798177084\n",
      "i would like to a\n",
      "soupsed down on again!  Alice was I the Dormouse.\n",
      "\n",
      "  `Well, I know!' said She reshes high, where where where to do she foots; and the poolar some up and was looked at Alice\n",
      "From\n",
      "her adventures! \n",
      "\n",
      "\n",
      "<2023-05-28 20:40:48.275361> | epoch: 1920/4000 | loss: 1.0268824259440104\n",
      "i would like a tucking the party out the found her at all in:  Alice hastily she looked\n",
      "another.\n",
      "`Now, the baby one to the court, to look this to\n",
      "fan confused.  You goy of them looked at all down in a thory\n",
      "all t\n",
      "\n",
      "\n",
      "<2023-05-28 20:42:07.179361> | epoch: 2080/4000 | loss: 1.2973768107096355\n",
      "i would like the door, was a house\n",
      "\n",
      "\n",
      "\n",
      "                                                              CHAPTER IV\n",
      "\n",
      "                                               CHAPTER IV\n",
      "\n",
      "                                        W\n",
      "\n",
      "\n",
      "<2023-05-28 20:43:24.908360> | epoch: 2240/4000 | loss: 1.2878619384765626\n",
      "i would like cheered, where you and marked managed into the sea,' the Mock Turtle\n",
      "said:\n",
      "  `I won't generally this tea--and both\n",
      "concert of her tea--'\n",
      "\n",
      "  She could go and caution.\n",
      "\n",
      "  There said to Alice adventured\n",
      "\n",
      "\n",
      "<2023-05-28 20:44:43.725389> | epoch: 2400/4000 | loss: 1.0854092407226563\n",
      "i would like the venture the same white strange.\n",
      "\n",
      "  `I'm not see so severely your tongue!' said the Cat.\n",
      "\n",
      "  `I have no finting yet,' she asked the Gryphon.\n",
      "\n",
      "  Alice presents\n",
      "wandered.\n",
      "\n",
      "  `Then the white Rabbit ex\n",
      "\n",
      "\n",
      "<2023-05-28 20:46:02.291360> | epoch: 2560/4000 | loss: 0.7228055826822917\n",
      "i would like to get be?' she said in a low, it would be of nearerly as he could; and, as she succeeded herself, and she shooke, she\n",
      "could the Knave if about his taid.  `We way,' said the King; and was an eagerly.\n",
      "\n",
      "\n",
      "<2023-05-28 20:47:20.932389> | epoch: 2720/4000 | loss: 1.1804288736979167\n",
      "i would like the reason of getting in the slate\n",
      "`arches croqueted the middle of criad, from what lobster another popere, my and took the othart, who changed in advantair, `that it would curious to make up, I had \n",
      "\n",
      "\n",
      "<2023-05-28 20:48:39.462361> | epoch: 2880/4000 | loss: 0.9048402913411459\n",
      "i would like their.\n",
      "\n",
      "  `You should not think you!' he went on\n",
      "it, feeling at last it\n",
      "altogether; and as she seemed to have like it had a little flying housed idea once is--oh came upon her.\n",
      "\n",
      "  `What a bit,' said \n",
      "\n",
      "\n",
      "<2023-05-28 20:49:58.474389> | epoch: 3040/4000 | loss: 0.9926163736979167\n",
      "i would like his eyes at this now, who wondering her head smying everything when thought the Queen she was into the Mouse stilled out it; `but\n",
      "after it, you\n",
      "know--and bit is\n",
      "makes me goose?'\n",
      "\n",
      "  `Thanking of my he\n",
      "\n",
      "\n",
      "<2023-05-28 20:51:14.101360> | epoch: 3200/4000 | loss: 1.0576805623372396\n",
      "i would like a thing; and a large right finished him.  At lasted the Queen.  She\n",
      "went do the Queen.\n",
      "\n",
      "  `What IS the trial's sitting at all thimble the-write she heard a while, then such a Lizard!'\n",
      "\n",
      "  This seen a \n",
      "\n",
      "\n",
      "<2023-05-28 20:52:29.524383> | epoch: 3360/4000 | loss: 0.6690015665690104\n",
      "i would like sike.  `I can't remember in their hustly, sight little carticupressed it to think you know, they say you those might best and solemp that by that cup into all prishortable were sharing at Alice for l\n",
      "\n",
      "\n",
      "<2023-05-28 20:53:45.165360> | epoch: 3520/4000 | loss: 0.8242060343424479\n",
      "i would like\".  `I can't have lesson'lens thought, and\n",
      "went on WHATESESY feel on smaller, I can exclime with her air off\n",
      "wish have Ellsitte\n",
      "fief one living\n",
      "you change?'\n",
      "\n",
      "  The King last lady, `I see it\n",
      "suppose El\n",
      "\n",
      "\n",
      "<2023-05-28 20:55:01.120361> | epoch: 3680/4000 | loss: 0.5326940409342448\n",
      "i would like.\n",
      "\n",
      "  There was gone, she ran as he had to look holding for her arms would, and the whole place one here, `the's voice!  They're good-Mayy by, and\n",
      "say when she had not know, and she soon is it began.  \n",
      "\n",
      "\n",
      "<2023-05-28 20:56:17.586390> | epoch: 3840/4000 | loss: 0.8110408528645834\n",
      "i would like to cry that!'\n",
      "\n",
      "  `I don't know down a way I do!' he could not on eel talking anxiously that she tried to makes being round her; the matter with one eye; to get in\n",
      "her try at them, which was so large \n",
      "\n",
      "\n",
      "<2023-05-28 20:57:33.602359> | epoch: 4000/4000 | loss: 0.7943873087565104\n",
      "i would like a starts, and then,' the Marrch Hare moment this remark,\n",
      "      But I should manage the crumbsforrying inches in\n",
      "Wonder, as well scale!' (onderstand notion.  Alice tail, she\n",
      "had head much overselves: \n"
     ]
    }
   ],
   "source": [
    "gentext = Generator()\n",
    "gentext.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i would like the Dormouse close to of their faces.  `I don't take song to go!  The Duchess!  The Footman said to the Dormouse,' said the Hatter.  `Oh my tea with the moon,\\n    And they're mulaully fetching their slates--and I've got to be an old panch is as you could not.'\\n\\n  `The lobsters!' said the Duchess; `I\\nought to be a book to try the hedgehos, or the jury.\\n\\n                                            \""
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gentext.generate(initial_str='i would like', predict_len=400, temperature=0.65)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = nn.Linear(512, 100)\n",
    "# input = torch.randn(1, 512)\n",
    "# output = m(input)\n",
    "# print(output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
