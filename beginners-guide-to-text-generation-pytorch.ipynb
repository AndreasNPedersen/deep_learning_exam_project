{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Beginners Guide to Text Generation using GRUs**\n",
    "\n",
    "Text Generation is a type of Language Modelling problem. Language Modelling is the core problem for a number of of natural language processing tasks such as speech to text, conversational system, and text summarization. A trained language model learns the likelihood of occurrence of a word based on the previous sequence of words used in the text. Language models can be operated at character level, n-gram level, sentence level or even paragraph level. In this notebook, I will explain how to create a language model for generating natural language text by implement and training state-of-the-art Recurrent Neural Network."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import the libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import string\n",
    "import unidecode\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on GPU!\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "if(train_on_gpu):\n",
    "    print('Training on GPU!')\n",
    "else: \n",
    "    print('No GPU available, training on CPU; consider making n_epochs very small.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    WASHINGTON (Reuters) - The head of a conservat...\n",
       "1    WASHINGTON (Reuters) - Transgender people will...\n",
       "2    WASHINGTON (Reuters) - The special counsel inv...\n",
       "3    WASHINGTON (Reuters) - Trump campaign adviser ...\n",
       "4    SEATTLE/WASHINGTON (Reuters) - President Donal...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('data/True.csv')\n",
    "author = train_df['text']\n",
    "author[:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42118"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = list(author[:100])\n",
    "def joinStrings(text):\n",
    "    return ' '.join(string for string in text)\n",
    "text = joinStrings(text)\n",
    "# text = [item for sublist in author[:5].values for item in sublist]\n",
    "len(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mrull\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mrull\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\mrull\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "stop = set(nltk.corpus.stopwords.words('english'))\n",
    "exclude = set(string.punctuation) \n",
    "lemma = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "def clean(doc):\n",
    "        stop_free = \" \".join([i for i in doc.split() if i not in stop])\n",
    "        punc_free = \"\".join(ch for ch in stop_free if ch not in exclude)\n",
    "        normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "        return normalized\n",
    "test_sentence = clean(text).lower().split()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **N-Gram Language Modeling**\n",
    "\n",
    "Recall that in an n-gram language model, given a sequence of words w, we want to compute.\n",
    "                                      * P(wi|wi−1,wi−2,…,wi−n+1)                                                     \n",
    "Where wi is the ith word of the sequence.                                                                              here we will take n=2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['washington', 'reuters'], 'the'), (['reuters', 'the'], 'head'), (['the', 'head'], 'conservative')]\n"
     ]
    }
   ],
   "source": [
    "trigrams = [([test_sentence[i], test_sentence[i + 1]], test_sentence[i + 2])\n",
    "            for i in range(len(test_sentence) - 2)]\n",
    "chunk_len=len(trigrams)\n",
    "print(trigrams[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(test_sentence)\n",
    "voc_len=len(vocab)\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp=[]\n",
    "tar=[]\n",
    "for context, target in trigrams:\n",
    "        context_idxs = torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n",
    "        inp.append(context_idxs)\n",
    "        targ = torch.tensor([word_to_ix[target]], dtype=torch.long)\n",
    "        tar.append(targ)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GRU model for Text Generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size*2, hidden_size, n_layers,batch_first=True,\n",
    "                          bidirectional=False)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        input = self.encoder(input.view(1, -1))\n",
    "        output, hidden = self.gru(input.view(1, 1, -1), hidden)\n",
    "        output = self.decoder(output.view(1, -1))\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return Variable(torch.zeros(self.n_layers, 1, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(inp, target):\n",
    "    hidden = decoder.init_hidden().cuda()\n",
    "    decoder.zero_grad()\n",
    "    loss = 0\n",
    "    \n",
    "    for c in range(chunk_len):\n",
    "        output, hidden = decoder(inp[c].cuda(), hidden)\n",
    "        loss += criterion(output, target[c].cuda())\n",
    "\n",
    "    loss.backward()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data.item() / chunk_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, math\n",
    "\n",
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0m 28s (1 0%) 8.6957]\n",
      "[0m 58s (2 1%) 8.5145]\n",
      "[1m 28s (3 1%) 7.8783]\n",
      "[1m 58s (4 2%) 7.7847]\n",
      "[2m 28s (5 2%) 7.5964]\n",
      "[2m 59s (6 3%) 7.4108]\n",
      "[3m 29s (7 3%) 7.2725]\n",
      "[3m 59s (8 4%) 7.1356]\n",
      "[4m 29s (9 4%) 6.9714]\n",
      "[4m 58s (10 5%) 6.7868]\n",
      "[5m 28s (11 5%) 6.5849]\n",
      "[5m 59s (12 6%) 6.3671]\n",
      "[6m 28s (13 6%) 6.1384]\n",
      "[6m 59s (14 7%) 5.9125]\n",
      "[7m 30s (15 7%) 5.6754]\n",
      "[8m 5s (16 8%) 5.4246]\n",
      "[8m 41s (17 8%) 5.1669]\n",
      "[9m 16s (18 9%) 4.9048]\n",
      "[9m 52s (19 9%) 4.6394]\n",
      "[10m 28s (20 10%) 4.3722]\n",
      "[11m 4s (21 10%) 4.1054]\n",
      "[11m 39s (22 11%) 3.8422]\n",
      "[12m 16s (23 11%) 3.5845]\n",
      "[12m 52s (24 12%) 3.3353]\n",
      "[13m 28s (25 12%) 3.0959]\n",
      "[14m 4s (26 13%) 2.8675]\n",
      "[14m 37s (27 13%) 2.6501]\n",
      "[15m 13s (28 14%) 2.4441]\n",
      "[15m 49s (29 14%) 2.2488]\n",
      "[16m 25s (30 15%) 2.0642]\n",
      "[17m 1s (31 15%) 1.8902]\n",
      "[17m 37s (32 16%) 1.7269]\n",
      "[18m 14s (33 16%) 1.5739]\n",
      "[18m 50s (34 17%) 1.4312]\n",
      "[19m 26s (35 17%) 1.2984]\n",
      "[20m 3s (36 18%) 1.1757]\n",
      "[20m 39s (37 18%) 1.0643]\n",
      "[21m 16s (38 19%) 0.9632]\n",
      "[21m 52s (39 19%) 0.8666]\n",
      "[22m 28s (40 20%) 0.7746]\n",
      "[23m 4s (41 20%) 0.6961]\n",
      "[23m 41s (42 21%) 0.6255]\n",
      "[24m 16s (43 21%) 0.5576]\n",
      "[24m 52s (44 22%) 0.4987]\n",
      "[25m 28s (45 22%) 0.4468]\n",
      "[26m 3s (46 23%) 0.3975]\n",
      "[26m 39s (47 23%) 0.3552]\n",
      "[27m 15s (48 24%) 0.3175]\n",
      "[27m 51s (49 24%) 0.2830]\n",
      "[28m 27s (50 25%) 0.2533]\n",
      "[29m 3s (51 25%) 0.2260]\n",
      "[29m 39s (52 26%) 0.2021]\n",
      "[30m 15s (53 26%) 0.1810]\n",
      "[30m 52s (54 27%) 0.1620]\n",
      "[31m 28s (55 27%) 0.1457]\n",
      "[32m 5s (56 28%) 0.1308]\n",
      "[32m 41s (57 28%) 0.1179]\n",
      "[33m 17s (58 28%) 0.1064]\n",
      "[33m 53s (59 29%) 0.0963]\n",
      "[34m 29s (60 30%) 0.0873]\n",
      "[35m 4s (61 30%) 0.0794]\n",
      "[35m 40s (62 31%) 0.0724]\n",
      "[36m 16s (63 31%) 0.0661]\n",
      "[36m 51s (64 32%) 0.0605]\n",
      "[37m 26s (65 32%) 0.0557]\n",
      "[38m 3s (66 33%) 0.0513]\n",
      "[38m 38s (67 33%) 0.0474]\n",
      "[39m 14s (68 34%) 0.0440]\n",
      "[39m 50s (69 34%) 0.0409]\n",
      "[40m 25s (70 35%) 0.0381]\n",
      "[41m 1s (71 35%) 0.0357]\n",
      "[41m 37s (72 36%) 0.0335]\n",
      "[42m 12s (73 36%) 0.0316]\n",
      "[42m 48s (74 37%) 0.0297]\n",
      "[43m 23s (75 37%) 0.0281]\n",
      "[43m 58s (76 38%) 0.0266]\n",
      "[44m 34s (77 38%) 0.0252]\n",
      "[45m 10s (78 39%) 0.0240]\n",
      "[45m 45s (79 39%) 0.0229]\n",
      "[46m 21s (80 40%) 0.0221]\n",
      "[46m 57s (81 40%) 0.0210]\n",
      "[47m 33s (82 41%) 0.0202]\n",
      "[48m 9s (83 41%) 0.0193]\n",
      "[48m 45s (84 42%) 0.0186]\n",
      "[49m 21s (85 42%) 0.0179]\n",
      "[49m 57s (86 43%) 0.0173]\n",
      "[50m 33s (87 43%) 0.0166]\n",
      "[51m 9s (88 44%) 0.0161]\n",
      "[51m 45s (89 44%) 0.0156]\n",
      "[52m 20s (90 45%) 0.0151]\n",
      "[52m 56s (91 45%) 0.0146]\n",
      "[53m 32s (92 46%) 0.0142]\n",
      "[54m 7s (93 46%) 0.0138]\n",
      "[54m 42s (94 47%) 0.0134]\n",
      "[55m 17s (95 47%) 0.0131]\n",
      "[55m 53s (96 48%) 0.0128]\n",
      "[56m 28s (97 48%) 0.0124]\n",
      "[57m 4s (98 49%) 0.0122]\n",
      "[57m 40s (99 49%) 0.0119]\n",
      "[58m 15s (100 50%) 0.0117]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "print_every = (n_epochs // 20) or 1\n",
    "plot_every = 1\n",
    "hidden_size = 100\n",
    "n_layers = 2\n",
    "lr = 0.015\n",
    "\n",
    "decoder = RNN(voc_len, hidden_size, voc_len, n_layers)\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "start = time.time()\n",
    "all_losses = []\n",
    "loss_avg = 0\n",
    "if(train_on_gpu):\n",
    "    decoder.cuda()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    loss = train(inp,tar)       \n",
    "    loss_avg += loss\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 50, loss))\n",
    "#         print(evaluate('ge', 200), '\\n')\n",
    "\n",
    "    if epoch % plot_every == 0:\n",
    "        all_losses.append(loss_avg / plot_every)\n",
    "        loss_avg = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x287c9cb1370>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "torch.save(decoder.state_dict(), \"savedModel.pt\")\n",
    "plt.figure()\n",
    "plt.plot(all_losses)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generating the text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(prime_str='this process', predict_len=100, temperature=0.8):\n",
    "    hidden = decoder.init_hidden().cuda()\n",
    "\n",
    "    for p in range(predict_len):\n",
    "        \n",
    "        prime_input = torch.tensor([word_to_ix[w] for w in prime_str.split()], dtype=torch.long).cuda()\n",
    "        inp = prime_input[-2:] #last two words as input\n",
    "        output, hidden = decoder(inp, hidden)\n",
    "        \n",
    "        # Sample from the network as a multinomial distribution\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        \n",
    "        # Add predicted word to string and use as next input\n",
    "        predicted_word = list(word_to_ix.keys())[list(word_to_ix.values()).index(top_i)]\n",
    "        prime_str += \" \" + predicted_word\n",
    "#         inp = torch.tensor(word_to_ix[predicted_word], dtype=torch.long)\n",
    "\n",
    "    return prime_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this process courted partner dennis graft reunification arctic source right harry january” right loan right appreciating infrastructure source minor preserves taxdodging right jackie regain mark porcupine battle wednesday creates bill’s business cap particularly change company repeals still small fuel escalating incumbent dreamers\n"
     ]
    }
   ],
   "source": [
    "print(evaluate('this process', 40, temperature=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "donald trump is a pressed criticized tweet dinner diplomat 31 try tie giftwrapped although jumped salt puerto record thursday thursday rule wave step graham banking finding tuesday chuck record republican republican ford afterward us\n"
     ]
    }
   ],
   "source": [
    "print(evaluate('donald trump is a', 30, temperature=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "donald trump is a exchange restriction loyal malpractice” clinched covering speech washington reuters murkowski asked republican presidential republican party trump candidate politician economy cost bond right alaska lawful allow officially itemizing ahead deportation two\n"
     ]
    }
   ],
   "source": [
    "print(evaluate('donald trump is a', 30, temperature=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'load in the model:'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"load in the model:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mrull\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mrull\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\mrull\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['washington', 'reuters'], 'the'), (['reuters', 'the'], 'head'), (['the', 'head'], 'conservative')]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import string\n",
    "import unidecode\n",
    "import random\n",
    "import torch\n",
    "\n",
    "train_df = pd.read_csv('data/True.csv')\n",
    "author = train_df['text']\n",
    "## clan dataset\n",
    "text = list(author[:100])\n",
    "def joinStrings(text):\n",
    "    return ' '.join(string for string in text)\n",
    "text = joinStrings(text)\n",
    "# text = [item for sublist in author[:5].values for item in sublist]\n",
    "len(text.split())\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "stop = set(nltk.corpus.stopwords.words('english'))\n",
    "exclude = set(string.punctuation) \n",
    "lemma = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "def clean(doc):\n",
    "        stop_free = \" \".join([i for i in doc.split() if i not in stop])\n",
    "        punc_free = \"\".join(ch for ch in stop_free if ch not in exclude)\n",
    "        normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "        return normalized\n",
    "test_sentence = clean(text).lower().split()\n",
    "\n",
    "##N-Gram model\n",
    "trigrams = [([test_sentence[i], test_sentence[i + 1]], test_sentence[i + 2])\n",
    "            for i in range(len(test_sentence) - 2)]\n",
    "chunk_len=len(trigrams)\n",
    "print(trigrams[:3])\n",
    "vocab = set(test_sentence)\n",
    "voc_len=len(vocab)\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
    "inp=[]\n",
    "tar=[]\n",
    "for context, target in trigrams:\n",
    "        context_idxs = torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n",
    "        inp.append(context_idxs)\n",
    "        targ = torch.tensor([word_to_ix[target]], dtype=torch.long)\n",
    "        tar.append(targ)\n",
    "\n",
    "## RNN model:\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "hidden_size = 100\n",
    "n_layers = 3\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size*2, hidden_size, n_layers,batch_first=True,\n",
    "                          bidirectional=False)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        input = self.encoder(input.view(1, -1))\n",
    "        output, hidden = self.gru(input.view(1, 1, -1), hidden)\n",
    "        output = self.decoder(output.view(1, -1))\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return Variable(torch.zeros(self.n_layers, 1, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(prime_str='this process', predict_len=100, temperature=0.8):\n",
    "    decoder = RNN(voc_len, hidden_size, voc_len, n_layers)\n",
    "    decoder.load_state_dict(torch.load(\"savedModel.pt\"))\n",
    "    decoder.cuda()\n",
    "    hidden = decoder.init_hidden().cuda()\n",
    "\n",
    "    for p in range(predict_len):\n",
    "        \n",
    "        prime_input = torch.tensor([word_to_ix[w] for w in prime_str.split()], dtype=torch.long).cuda()\n",
    "        inp = prime_input[-2:] #last two words as input\n",
    "        output, hidden = decoder(inp, hidden)\n",
    "        \n",
    "        # Sample from the network as a multinomial distribution\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        \n",
    "        # Add predicted word to string and use as next input\n",
    "        predicted_word = list(word_to_ix.keys())[list(word_to_ix.values()).index(top_i)]\n",
    "        prime_str += \" \" + predicted_word\n",
    "#         inp = torch.tensor(word_to_ix[predicted_word], dtype=torch.long)\n",
    "\n",
    "    return prime_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, math\n",
    "\n",
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for RNN:\n\tMissing key(s) in state_dict: \"gru.weight_ih_l2\", \"gru.weight_hh_l2\", \"gru.bias_ih_l2\", \"gru.bias_hh_l2\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(evaluate(\u001b[39m'\u001b[39;49m\u001b[39mtrump is\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m30\u001b[39;49m, temperature\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m))\n",
      "Cell \u001b[1;32mIn[52], line 3\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(prime_str, predict_len, temperature)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluate\u001b[39m(prime_str\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mthis process\u001b[39m\u001b[39m'\u001b[39m, predict_len\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, temperature\u001b[39m=\u001b[39m\u001b[39m0.8\u001b[39m):\n\u001b[0;32m      2\u001b[0m     decoder \u001b[39m=\u001b[39m RNN(voc_len, hidden_size, voc_len, n_layers)\n\u001b[1;32m----> 3\u001b[0m     decoder\u001b[39m.\u001b[39;49mload_state_dict(torch\u001b[39m.\u001b[39;49mload(\u001b[39m\"\u001b[39;49m\u001b[39msavedModel.pt\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[0;32m      4\u001b[0m     decoder\u001b[39m.\u001b[39mcuda()\n\u001b[0;32m      5\u001b[0m     hidden \u001b[39m=\u001b[39m decoder\u001b[39m.\u001b[39minit_hidden()\u001b[39m.\u001b[39mcuda()\n",
      "File \u001b[1;32md:\\dev\\bachelor\\deep_learning\\env_test\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:2041\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   2036\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[0;32m   2037\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   2038\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[0;32m   2040\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m-> 2041\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   2042\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   2043\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for RNN:\n\tMissing key(s) in state_dict: \"gru.weight_ih_l2\", \"gru.weight_hh_l2\", \"gru.bias_ih_l2\", \"gru.bias_hh_l2\". "
     ]
    }
   ],
   "source": [
    "print(evaluate('trump is', 30, temperature=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
